import os
import pandas as pd
import streamlit as st
from scripts.feature_generator import FeatureEngineer
from scripts.dataset_merger import ProcessedDataGenerator
from scripts.cluster_model import UserBehaviorClustering  # Gerekli modÃ¼ller

# Streamlit baÅŸlÄ±ÄŸÄ±
st.title("Model EÄŸitim ve SonuÃ§ GÃ¶rÃ¼ntÃ¼leme")

# Streamlit session_state kontrolÃ¼
if 'feature_engineered' not in st.session_state:
    st.session_state.feature_engineered = False
if 'data_processed' not in st.session_state:
    st.session_state.data_processed = False
if 'model_trained' not in st.session_state:
    st.session_state.model_trained = False

# 1. Feature dataset creation
st.subheader("1. Feature Dataset Creation")
base_data_path = "data/advanced_user_events_with_uuid.csv"
feature_data_path = "./feature_data"

st.text(f"Base Data Path: {base_data_path}")
st.text(f"Feature Data Path: {feature_data_path}")

# Feature Engineer iÅŸlemi
if st.button("Feature Engineering BaÅŸlat") and not st.session_state.feature_engineered:
    st.text("Feature Engineering BaÅŸlatÄ±lÄ±yor...")
    feature_engineer = FeatureEngineer(base_data_path, feature_data_path)
    feature_engineer.run()
    st.session_state.feature_engineered = True
    st.text("Feature Engineering TamamlandÄ±!")

# 2. Dataset processor and merger
if st.session_state.feature_engineered:
    st.subheader("2. Dataset Processor and Merger")
    features_path = "./feature_data" 
    demog_data_path = "data/advanced_user_profiles_with_uuid.csv"
    output_path = "final_datasets/final_data.csv" 

    st.text(f"Features Path: {features_path}")
    st.text(f"Categorical Data Path: {demog_data_path}")
    st.text(f"Output Path: {output_path}")

    # Veri iÅŸleme iÅŸlemi
    if st.button("Veri Ä°ÅŸleme ve BirleÅŸtirme BaÅŸlat") and not st.session_state.data_processed:
        st.text("Veri iÅŸleniyor...")
        processor = ProcessedDataGenerator(features_path, demog_data_path, output_path)
        processor.run()
        st.session_state.data_processed = True
        st.text("Veri iÅŸleme tamamlandÄ±!")

# 3. Cluster model training ve kaydetme
if st.session_state.data_processed:
    st.subheader("3. Cluster Model Training ve Kaydetme")
    if st.button("Model EÄŸitimi BaÅŸlat") and not st.session_state.model_trained:
        st.text("Model EÄŸitimi BaÅŸlatÄ±lÄ±yor...")
        clustering = UserBehaviorClustering(
            df_path="final_datasets/final_data.csv",
            n_clusters=3
        )

        cluster_label_map = {
            0: "Growth Potential",
            1: "Churn Risk",
            2: "High Value Users"
        }

        df_with_clusters = clustering.run(cluster_labels=cluster_label_map)
        st.session_state.model_trained = True
        st.text("Model EÄŸitimi TamamlandÄ±!")

        # KullanÄ±cÄ± ve tahmin edilen davranÄ±ÅŸ segmentini iÃ§eren dataframe
        user_segment_df = df_with_clusters[["user_id", "behavior_segment"]]

        # KayÄ±t iÅŸlemi
        output_path = "result_show/user_behavior_segments.csv"
        user_segment_df.to_csv(output_path, index=False)

        st.text(f"KullanÄ±cÄ± segmentleri '{output_path}' dosyasÄ±na kaydedildi.")

        # SonuÃ§larÄ± doÄŸrudan gÃ¶ster
        st.subheader("Model SonuÃ§larÄ±")
        st.dataframe(user_segment_df, height=300)

        # GÃ¶rsel ve .txt dosyalarÄ±nÄ± da gÃ¶ster
        st.subheader("SonuÃ§larÄ± GÃ¶rÃ¼ntÃ¼le")
        result_show_dir = "result_show"
        result_files = os.listdir(result_show_dir)
        images = [file for file in result_files if file.endswith(('.png', '.jpg', '.jpeg'))]
        txt_files = [file for file in result_files if file.endswith('.txt')]

        st.write("Resimler:")
        for image in images:
            img_path = os.path.join(result_show_dir, image)
            st.image(img_path, caption=image)

st.subheader("4. UygulamayÄ± Yeniden BaÅŸlatma")
if st.button("ğŸ” Yeniden BaÅŸlat"):
    st.session_state.clear()
    st.experimental_rerun()


